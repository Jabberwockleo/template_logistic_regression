{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph config\n",
    "FEATURE_NUM = 4\n",
    "\n",
    "# Training config\n",
    "LEARNING_RATE = 0.001\n",
    "EPOCHES = 10\n",
    "BATCH_SIZE = 1\n",
    "DISPLAY_STEP = 100\n",
    "\n",
    "# output dir\n",
    "CHKPT_DIR = '/tmp/chkpt/lr'\n",
    "LOG_DIR = '/tmp/log/lr'\n",
    "MODEL_DIR = '/tmp/model/lr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample data\n",
    "\n",
    "# iris data\n",
    "from sklearn import datasets\n",
    "dataset_ori = datasets.load_iris(return_X_y=True)\n",
    "y_label = map(lambda x: x == 0, dataset_ori[1])\n",
    "dataset = []\n",
    "dataset.append(dataset_ori[0])\n",
    "dataset.append(np.array(list(y_label)).astype(int))\n",
    "\n",
    "# mock data\n",
    "def mock_boundary_func(X):\n",
    "    # mock weights is (1, 2, 3, ..)\n",
    "    return np.sum(np.dot(X, list(range(1, len(X) + 1))))\n",
    "dataset = []\n",
    "dataset.append(np.random.standard_normal(size=(1000, FEATURE_NUM)))\n",
    "dataset.append(np.array(list(map(lambda x: mock_boundary_func(x) >= 0, dataset[0]))).astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch util\n",
    "def batch(iterable, n=1):\n",
    "    l = len(iterable)\n",
    "    for ndx in range(0, l, n):\n",
    "        yield iterable[ndx:min(ndx + n, l)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([-0.66648262,  2.01710989,  1.26082899,  0.04385765]), array([-0.60630516, -0.66185479, -0.46579354, -0.03129897]), array([-0.11115686,  0.3770051 ,  0.04170284,  0.18289504])) (1, 0, 1)\n"
     ]
    }
   ],
   "source": [
    "# test batch\n",
    "for tu in batch(list(zip(dataset[0], dataset[1])), n=3):\n",
    "    X, y = zip(*tu)\n",
    "    print(X, y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegressor(object):\n",
    "    \"\"\"\n",
    "        Logistic Regressor\n",
    "    \"\"\"\n",
    "    def __init__(self, feature_num, learning_rate=1e-2, random_seed=None):\n",
    "        \"\"\"\n",
    "            Initializer\n",
    "            Params:\n",
    "                feature_num: feature number\n",
    "                learning_rate: learning rate\n",
    "                random_seed: random seed\n",
    "        \"\"\"\n",
    "        self.feature_num = feature_num\n",
    "        self.learning_rate = learning_rate\n",
    "        self.random_seed = random_seed\n",
    "        self.construct_placeholders()\n",
    "        \n",
    "    def construct_placeholders(self):\n",
    "        \"\"\"\n",
    "            Construct inpute placeholders\n",
    "        \"\"\"\n",
    "        self.input_feature_vectors = tf.placeholder(shape=[None, self.feature_num],\n",
    "            dtype=tf.float32)\n",
    "        self.input_labels = tf.placeholder(shape=[None, 1],\n",
    "            dtype=tf.float32)\n",
    "    \n",
    "    def build_graph(self):\n",
    "        \"\"\"\n",
    "            Build graph\n",
    "        \"\"\"\n",
    "        self.construct_weights()\n",
    "        \n",
    "        # network forward pass\n",
    "        saver, logits = self.forward_pass()\n",
    "        \n",
    "        # loss function\n",
    "        loss = tf.reduce_mean(\n",
    "            tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "            logits=logits, labels=self.input_labels))\n",
    "        \n",
    "        # training optimizer\n",
    "        train_op = tf.train.GradientDescentOptimizer(self.learning_rate).minimize(loss)\n",
    "        \n",
    "        # statistics\n",
    "        tf.summary.scalar('loss', loss)\n",
    "        stat_merged = tf.summary.merge_all()\n",
    "\n",
    "        return saver, logits, loss, train_op, stat_merged\n",
    "    \n",
    "    def construct_weights(self):\n",
    "        \"\"\"\n",
    "            Construct weights\n",
    "        \"\"\"\n",
    "        self.weights = []\n",
    "        self.biases = []\n",
    "        \n",
    "        for i in range(1):\n",
    "            weight_key = \"w_{}_{}\".format(i, i+1)\n",
    "            bias_key = \"b_{}\".format(i)\n",
    "            self.weights.append(tf.get_variable(\n",
    "                name=weight_key, shape=[self.feature_num, 1],\n",
    "                initializer=tf.contrib.layers.xavier_initializer(\n",
    "                    seed=self.random_seed)))\n",
    "            \n",
    "            self.biases.append(tf.get_variable(\n",
    "                name=bias_key, shape=[1],\n",
    "                initializer=tf.truncated_normal_initializer(\n",
    "                    stddev=0.001, seed=self.random_seed)))\n",
    "            \n",
    "            # statistics\n",
    "            tf.summary.histogram(weight_key, self.weights[-1])\n",
    "            tf.summary.histogram(bias_key, self.biases[-1])\n",
    "            \n",
    "    def forward_pass(self):\n",
    "        \"\"\"\n",
    "            Forward pass\n",
    "        \"\"\"\n",
    "        h = self.input_feature_vectors\n",
    "        \n",
    "        for i, (w, b) in enumerate(zip(self.weights, self.biases)):\n",
    "            h = tf.matmul(h, w) + b\n",
    "            \n",
    "            if i != len(self.weights) - 1:\n",
    "                h = tf.nn.sigmoid(h)\n",
    "\n",
    "        return tf.train.Saver(), h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def sigmoid(x):\n",
    "    \"\"\"\n",
    "        Sigmoid\n",
    "    \"\"\"\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def calc_accuracy(logits, labels):\n",
    "    \"\"\"\n",
    "        Calc accuracy\n",
    "    \"\"\"\n",
    "    pred_labels = np.round(sigmoid(logits))\n",
    "    match_score = np.equal(pred_labels, labels).astype(np.float32)\n",
    "    return np.mean(match_score)\n",
    "\n",
    "def calc_f1(logits, labels, log_confusion_matrix=False):\n",
    "    \"\"\"\n",
    "        Calc F1 score\n",
    "    \"\"\"\n",
    "    pred_labels = np.round(sigmoid(np.array(logits))).ravel()\n",
    "    real_labels = np.array(labels).ravel()\n",
    "    ind_1 = np.argwhere(real_labels == 1)\n",
    "    ind_0 = np.argwhere(real_labels == 0)\n",
    "    tp = np.sum(pred_labels[ind_1])\n",
    "    tn = np.sum((1 - pred_labels)[ind_0])\n",
    "    fp = np.sum(pred_labels[ind_0])\n",
    "    fn = np.sum((1 - pred_labels)[ind_1])\n",
    "    f1 = 2.0 * tp / (2*tp + fn + fp)\n",
    "    acc = (tp + tn) * 1.0 / (tp + tn + fp + fn)\n",
    "    if log_confusion_matrix is True:\n",
    "        print(\"tp:{}, tn:{}, fp:{}, fn:{}, acc:{}, len:{}\".format(\n",
    "        tp, tn, fp, fn, acc, len(logits)))\n",
    "    return f1\n",
    "\n",
    "def calc_auc(logits, labels):\n",
    "    \"\"\"\n",
    "        Calc AUC\n",
    "    \"\"\"\n",
    "    return roc_auc_score(labels, logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp:2.0, tn:1.0, fp:1.0, fn:0.0, acc:0.75, len:4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1, 1, 1, 0]\n",
    "b = [0, 1, 1, 0]\n",
    "calc_f1(a, b, log_confusion_matrix=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build graph\n",
    "tf.reset_default_graph()\n",
    "lr = LogisticRegressor(feature_num=FEATURE_NUM, learning_rate=LEARNING_RATE, random_seed=None)\n",
    "saver, logits, loss, train_op, stat_merged = lr.build_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, global_step: 100, loss: 0.520747721195221, accuracy: 0.75, f1: 0.7524752475247525, auc: 0.8207652503811844\n",
      "epoch: 0, global_step: 200, loss: 0.513968288898468, accuracy: 0.7540000081062317, f1: 0.7569169960474308, auc: 0.8271643475442114\n",
      "epoch: 0, global_step: 300, loss: 0.5047698616981506, accuracy: 0.7620000243186951, f1: 0.7652859960552268, auc: 0.8366649458337835\n",
      "epoch: 0, global_step: 400, loss: 0.4962655305862427, accuracy: 0.7720000147819519, f1: 0.776908023483366, auc: 0.845137046330424\n",
      "epoch: 0, global_step: 500, loss: 0.4899859130382538, accuracy: 0.7749999761581421, f1: 0.7800586510263929, auc: 0.8509998839438287\n",
      "epoch: 0, global_step: 600, loss: 0.4835447371006012, accuracy: 0.7820000052452087, f1: 0.786692759295499, auc: 0.8569627699806708\n",
      "epoch: 0, global_step: 700, loss: 0.47795069217681885, accuracy: 0.7839999794960022, f1: 0.7890625, auc: 0.8623293674138284\n",
      "epoch: 0, global_step: 800, loss: 0.4717045724391937, accuracy: 0.7879999876022339, f1: 0.79296875, auc: 0.8681361779101084\n",
      "epoch: 0, global_step: 900, loss: 0.46490490436553955, accuracy: 0.796999990940094, f1: 0.8007850834151129, auc: 0.8747193641722594\n",
      "epoch: 0, global_step: 1000, loss: 0.4582514464855194, accuracy: 0.800000011920929, f1: 0.803921568627451, auc: 0.8808783451190376\n",
      "epoch: 1, global_step: 1100, loss: 0.4532009959220886, accuracy: 0.8059999942779541, f1: 0.810546875, auc: 0.8855966287683238\n",
      "epoch: 1, global_step: 1200, loss: 0.4476829171180725, accuracy: 0.8090000152587891, f1: 0.8136585365853658, auc: 0.8907231099852329\n",
      "epoch: 1, global_step: 1300, loss: 0.44230133295059204, accuracy: 0.8140000104904175, f1: 0.8180039138943248, auc: 0.8956374885444555\n",
      "epoch: 1, global_step: 1400, loss: 0.43750759959220886, accuracy: 0.8199999928474426, f1: 0.8238747553816047, auc: 0.8998075068333073\n",
      "epoch: 1, global_step: 1500, loss: 0.43306294083595276, accuracy: 0.8220000267028809, f1: 0.8265107212475633, auc: 0.9034932907527242\n",
      "epoch: 1, global_step: 1600, loss: 0.42772266268730164, accuracy: 0.8240000009536743, f1: 0.8284600389863548, auc: 0.908383657690322\n",
      "epoch: 1, global_step: 1700, loss: 0.42291784286499023, accuracy: 0.8299999833106995, f1: 0.8336594911937377, auc: 0.9123335694476127\n",
      "epoch: 1, global_step: 1800, loss: 0.4183051884174347, accuracy: 0.8320000171661377, f1: 0.8352941176470589, auc: 0.9162874831418406\n",
      "epoch: 1, global_step: 1900, loss: 0.4135228395462036, accuracy: 0.8349999785423279, f1: 0.8377581120943953, auc: 0.9200933251693819\n",
      "epoch: 1, global_step: 2000, loss: 0.4083273410797119, accuracy: 0.8370000123977661, f1: 0.8394088669950739, auc: 0.924675542962794\n",
      "epoch: 2, global_step: 2100, loss: 0.40426865220069885, accuracy: 0.8420000076293945, f1: 0.844488188976378, auc: 0.9280851932335251\n",
      "epoch: 2, global_step: 2200, loss: 0.40022802352905273, accuracy: 0.8429999947547913, f1: 0.8456243854473943, auc: 0.9314188067024439\n",
      "epoch: 2, global_step: 2300, loss: 0.3952585458755493, accuracy: 0.8460000157356262, f1: 0.8484251968503937, auc: 0.9356368482345455\n",
      "epoch: 2, global_step: 2400, loss: 0.3916674256324768, accuracy: 0.847000002861023, f1: 0.8492610837438423, auc: 0.9384061885952801\n",
      "epoch: 2, global_step: 2500, loss: 0.38814449310302734, accuracy: 0.8500000238418579, f1: 0.8523622047244095, auc: 0.9409073991812036\n",
      "epoch: 2, global_step: 2600, loss: 0.3857187330722809, accuracy: 0.8500000238418579, f1: 0.8523622047244095, auc: 0.9422400441813837\n",
      "epoch: 2, global_step: 2700, loss: 0.3813968598842621, accuracy: 0.8519999980926514, f1: 0.8546168958742633, auc: 0.9457617486863641\n",
      "epoch: 2, global_step: 2800, loss: 0.37838056683540344, accuracy: 0.8579999804496765, f1: 0.8607843137254902, auc: 0.9475346067496669\n",
      "epoch: 2, global_step: 2900, loss: 0.37587133049964905, accuracy: 0.8579999804496765, f1: 0.8607843137254902, auc: 0.9488192285065972\n",
      "epoch: 2, global_step: 3000, loss: 0.3719524145126343, accuracy: 0.8619999885559082, f1: 0.8644400785854617, auc: 0.9519207296331424\n",
      "epoch: 3, global_step: 3100, loss: 0.3692074716091156, accuracy: 0.8679999709129333, f1: 0.8708414872798435, auc: 0.9535815334621957\n",
      "epoch: 3, global_step: 3200, loss: 0.36630526185035706, accuracy: 0.8709999918937683, f1: 0.873900293255132, auc: 0.9554824535074975\n",
      "epoch: 3, global_step: 3300, loss: 0.3625035881996155, accuracy: 0.8759999871253967, f1: 0.8791423001949318, auc: 0.9583358345439192\n",
      "epoch: 3, global_step: 3400, loss: 0.35926544666290283, accuracy: 0.8799999952316284, f1: 0.8828125, auc: 0.9606609599045938\n",
      "epoch: 3, global_step: 3500, loss: 0.35680487751960754, accuracy: 0.8820000290870667, f1: 0.884765625, auc: 0.9620216184633363\n",
      "epoch: 3, global_step: 3600, loss: 0.35423892736434937, accuracy: 0.8859999775886536, f1: 0.888235294117647, auc: 0.9637224416617644\n",
      "epoch: 3, global_step: 3700, loss: 0.3514270484447479, accuracy: 0.8880000114440918, f1: 0.8904109589041096, auc: 0.9654512784187548\n",
      "epoch: 3, global_step: 3800, loss: 0.3489297032356262, accuracy: 0.890999972820282, f1: 0.8934506353861192, auc: 0.9667839234189346\n",
      "epoch: 3, global_step: 3900, loss: 0.34666430950164795, accuracy: 0.890999972820282, f1: 0.8936585365853659, auc: 0.9676683514821173\n",
      "epoch: 3, global_step: 4000, loss: 0.3446333706378937, accuracy: 0.8949999809265137, f1: 0.8971596474045054, auc: 0.9686488260317994\n",
      "epoch: 4, global_step: 4100, loss: 0.34224218130111694, accuracy: 0.8970000147819519, f1: 0.8993157380254154, auc: 0.9700294942752292\n",
      "epoch: 4, global_step: 4200, loss: 0.3399014472961426, accuracy: 0.8980000019073486, f1: 0.900390625, auc: 0.9711780501762853\n",
      "epoch: 4, global_step: 4300, loss: 0.3373729884624481, accuracy: 0.8999999761581421, f1: 0.9021526418786693, auc: 0.9725667222935901\n",
      "epoch: 4, global_step: 4400, loss: 0.3349984288215637, accuracy: 0.9039999842643738, f1: 0.9058823529411765, auc: 0.9739954137802697\n",
      "epoch: 4, global_step: 4500, loss: 0.3328542411327362, accuracy: 0.906000018119812, f1: 0.907843137254902, auc: 0.9750359173840137\n",
      "epoch: 4, global_step: 4600, loss: 0.33087432384490967, accuracy: 0.9079999923706055, f1: 0.9098039215686274, auc: 0.976192477158945\n",
      "epoch: 4, global_step: 4700, loss: 0.32883477210998535, accuracy: 0.9100000262260437, f1: 0.9119373776908023, auc: 0.977164947834752\n",
      "epoch: 4, global_step: 4800, loss: 0.32708442211151123, accuracy: 0.9100000262260437, f1: 0.9119373776908023, auc: 0.9776972054474365\n",
      "epoch: 4, global_step: 4900, loss: 0.32511597871780396, accuracy: 0.9150000214576721, f1: 0.916911045943304, auc: 0.9785856354475566\n",
      "epoch: 4, global_step: 5000, loss: 0.3234056830406189, accuracy: 0.9160000085830688, f1: 0.91796875, auc: 0.9791178930602411\n",
      "epoch: 5, global_step: 5100, loss: 0.32160484790802, accuracy: 0.9169999957084656, f1: 0.9188660801564027, auc: 0.9798102281504247\n",
      "epoch: 5, global_step: 5200, loss: 0.31944918632507324, accuracy: 0.9179999828338623, f1: 0.919921875, auc: 0.9810868460334803\n",
      "epoch: 5, global_step: 5300, loss: 0.31768375635147095, accuracy: 0.9200000166893005, f1: 0.9217221135029354, auc: 0.9817991908083512\n",
      "epoch: 5, global_step: 5400, loss: 0.3159480392932892, accuracy: 0.9210000038146973, f1: 0.9227761485826002, auc: 0.9824395007183476\n",
      "epoch: 5, global_step: 5500, loss: 0.31427398324012756, accuracy: 0.9240000247955322, f1: 0.92578125, auc: 0.9832919132860305\n",
      "epoch: 5, global_step: 5600, loss: 0.31251847743988037, accuracy: 0.925000011920929, f1: 0.9266862170087976, auc: 0.9841723394122756\n",
      "epoch: 5, global_step: 5700, loss: 0.3109191656112671, accuracy: 0.9269999861717224, f1: 0.9287804878048781, auc: 0.984728608646585\n",
      "epoch: 5, global_step: 5800, loss: 0.30932074785232544, accuracy: 0.9279999732971191, f1: 0.9298245614035088, auc: 0.9852808759439569\n",
      "epoch: 5, global_step: 5900, loss: 0.307868093252182, accuracy: 0.9279999732971191, f1: 0.9298245614035088, auc: 0.9856610599530171\n",
      "epoch: 5, global_step: 6000, loss: 0.3064531981945038, accuracy: 0.9290000200271606, f1: 0.9307317073170732, auc: 0.9862693543675138\n",
      "epoch: 6, global_step: 6100, loss: 0.3049948811531067, accuracy: 0.9300000071525574, f1: 0.931640625, auc: 0.9867175713045113\n",
      "epoch: 6, global_step: 6200, loss: 0.3034825325012207, accuracy: 0.9309999942779541, f1: 0.9326829268292683, auc: 0.9870777456288844\n",
      "epoch: 6, global_step: 6300, loss: 0.3021947741508484, accuracy: 0.9319999814033508, f1: 0.9337231968810916, auc: 0.9873098579712581\n",
      "epoch: 6, global_step: 6400, loss: 0.3007018566131592, accuracy: 0.9330000281333923, f1: 0.9346341463414635, auc: 0.9878661272055674\n",
      "epoch: 6, global_step: 6500, loss: 0.29890745878219604, accuracy: 0.9359999895095825, f1: 0.9376218323586745, auc: 0.9888786172507494\n",
      "epoch: 6, global_step: 6600, loss: 0.2975615859031677, accuracy: 0.9359999895095825, f1: 0.9376218323586745, auc: 0.9892547993228722\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6, global_step: 6700, loss: 0.2961331009864807, accuracy: 0.9380000233650208, f1: 0.939453125, auc: 0.9898310782418691\n",
      "epoch: 6, global_step: 6800, loss: 0.2949445843696594, accuracy: 0.9390000104904175, f1: 0.9404878048780487, auc: 0.9901192177013675\n",
      "epoch: 6, global_step: 6900, loss: 0.29371726512908936, accuracy: 0.9390000104904175, f1: 0.9404878048780487, auc: 0.9904473765302406\n",
      "epoch: 6, global_step: 7000, loss: 0.2925560176372528, accuracy: 0.9399999976158142, f1: 0.94140625, auc: 0.9906754869356769\n",
      "epoch: 7, global_step: 7100, loss: 0.2912064790725708, accuracy: 0.9409999847412109, f1: 0.9423264907135875, auc: 0.9910876864402371\n",
      "epoch: 7, global_step: 7200, loss: 0.2900957763195038, accuracy: 0.9440000057220459, f1: 0.9450980392156862, auc: 0.9913278026564858\n",
      "epoch: 7, global_step: 7300, loss: 0.2888176739215851, accuracy: 0.9449999928474426, f1: 0.9460255152109912, auc: 0.9917680157196083\n",
      "epoch: 7, global_step: 7400, loss: 0.28758350014686584, accuracy: 0.9459999799728394, f1: 0.9469548133595285, auc: 0.9920881706746064\n",
      "epoch: 7, global_step: 7500, loss: 0.2864551246166229, accuracy: 0.9459999799728394, f1: 0.9469548133595285, auc: 0.9924203314404172\n",
      "epoch: 7, global_step: 7600, loss: 0.28518199920654297, accuracy: 0.9459999799728394, f1: 0.9469548133595285, auc: 0.9927084708999155\n",
      "epoch: 7, global_step: 7700, loss: 0.2840421497821808, accuracy: 0.949999988079071, f1: 0.9508840864440079, auc: 0.9930366297287887\n",
      "epoch: 7, global_step: 7800, loss: 0.28300172090530396, accuracy: 0.9509999752044678, f1: 0.9519136408243376, auc: 0.993280747881975\n",
      "epoch: 7, global_step: 7900, loss: 0.28200972080230713, accuracy: 0.9520000219345093, f1: 0.9529411764705882, auc: 0.9933207672513495\n",
      "epoch: 7, global_step: 8000, loss: 0.28095412254333496, accuracy: 0.9539999961853027, f1: 0.9549019607843138, auc: 0.9936049047739106\n",
      "epoch: 8, global_step: 8100, loss: 0.2798496186733246, accuracy: 0.9559999704360962, f1: 0.9568627450980393, auc: 0.993893044233409\n",
      "epoch: 8, global_step: 8200, loss: 0.2786373794078827, accuracy: 0.9570000171661377, f1: 0.957801766437684, auc: 0.9941691778820949\n",
      "epoch: 8, global_step: 8300, loss: 0.27753761410713196, accuracy: 0.9589999914169312, f1: 0.9598432908912831, auc: 0.994337259233469\n",
      "epoch: 8, global_step: 8400, loss: 0.2763543725013733, accuracy: 0.9599999785423279, f1: 0.9607843137254902, auc: 0.9947894781074039\n",
      "epoch: 8, global_step: 8500, loss: 0.2753574550151825, accuracy: 0.9620000123977661, f1: 0.9627450980392157, auc: 0.9950055827020278\n",
      "epoch: 8, global_step: 8600, loss: 0.2744898200035095, accuracy: 0.9620000123977661, f1: 0.9627450980392157, auc: 0.9950095846389653\n",
      "epoch: 8, global_step: 8700, loss: 0.273707777261734, accuracy: 0.9620000123977661, f1: 0.9627450980392157, auc: 0.9950696136930275\n",
      "epoch: 8, global_step: 8800, loss: 0.27286651730537415, accuracy: 0.9610000252723694, f1: 0.9618021547502449, auc: 0.9950696136930275\n",
      "epoch: 8, global_step: 8900, loss: 0.27184516191482544, accuracy: 0.9620000123977661, f1: 0.9627450980392157, auc: 0.9953337415309009\n",
      "epoch: 8, global_step: 9000, loss: 0.2710481584072113, accuracy: 0.9629999995231628, f1: 0.9636898920510304, auc: 0.9953057279723386\n",
      "epoch: 9, global_step: 9100, loss: 0.27005934715270996, accuracy: 0.9639999866485596, f1: 0.9647058823529412, auc: 0.9954858151345252\n",
      "epoch: 9, global_step: 9200, loss: 0.2692263424396515, accuracy: 0.9660000205039978, f1: 0.9666666666666667, auc: 0.9955298364408374\n",
      "epoch: 9, global_step: 9300, loss: 0.26838219165802, accuracy: 0.9670000076293945, f1: 0.9676787463271302, auc: 0.9956979177922115\n",
      "epoch: 9, global_step: 9400, loss: 0.2675097584724426, accuracy: 0.9670000076293945, f1: 0.9676787463271302, auc: 0.9959180243237726\n",
      "epoch: 9, global_step: 9500, loss: 0.26658523082733154, accuracy: 0.9670000076293945, f1: 0.9676787463271302, auc: 0.9960420843688345\n",
      "epoch: 9, global_step: 9600, loss: 0.26578524708747864, accuracy: 0.9679999947547913, f1: 0.9686888454011742, auc: 0.9961661444138963\n",
      "epoch: 9, global_step: 9700, loss: 0.2649872303009033, accuracy: 0.968999981880188, f1: 0.9696376101860921, auc: 0.9962701947742707\n",
      "epoch: 9, global_step: 9800, loss: 0.26415351033210754, accuracy: 0.9679999947547913, f1: 0.9686274509803922, auc: 0.9962982083328331\n",
      "epoch: 9, global_step: 9900, loss: 0.2631940543651581, accuracy: 0.968999981880188, f1: 0.9696376101860921, auc: 0.9965503303598942\n",
      "epoch: 9, global_step: 10000, loss: 0.2624383866786957, accuracy: 0.9670000076293945, f1: 0.9676787463271302, auc: 0.9964742935580821\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    \n",
    "    # log dir\n",
    "    log_dir = LOG_DIR\n",
    "    if os.path.exists(log_dir):\n",
    "        shutil.rmtree(log_dir)\n",
    "    summary_writer = tf.summary.FileWriter(log_dir, graph=tf.get_default_graph())\n",
    "    \n",
    "    # checkpoint dir\n",
    "    chkpt_dir = CHKPT_DIR\n",
    "    if os.path.exists(chkpt_dir):\n",
    "        shutil.rmtree(chkpt_dir)\n",
    "    if not os.path.isdir(chkpt_dir):\n",
    "        os.makedirs(chkpt_dir)\n",
    "    \n",
    "    for epoch in range(EPOCHES):\n",
    "        batch_cnt = 0\n",
    "        batches_per_epoch = math.floor((len(dataset[0]) - 1) * 1.0 / BATCH_SIZE) + 1\n",
    "        best_loss = np.inf\n",
    "        cur_loss = np.inf\n",
    "        cur_accuracy = 0\n",
    "        training_data = list(zip(dataset[0], dataset[1]))\n",
    "        random.shuffle(training_data)\n",
    "        for tu in batch(training_data, n=BATCH_SIZE):\n",
    "            X, y = zip(*tu)\n",
    "            y = np.expand_dims(y, 1)\n",
    "            feed_dict = {\n",
    "                lr.input_feature_vectors: X,\n",
    "                lr.input_labels: y\n",
    "            }\n",
    "            sess.run(train_op, feed_dict=feed_dict)\n",
    "            batch_cnt += 1\n",
    "            global_step = epoch * batches_per_epoch + batch_cnt\n",
    "            if global_step % DISPLAY_STEP == 0:\n",
    "                in_f = dataset[0]\n",
    "                in_l = np.expand_dims(dataset[1], 1)\n",
    "                feed_dict = {\n",
    "                    lr.input_feature_vectors: in_f,\n",
    "                    lr.input_labels: in_l\n",
    "                }\n",
    "                cur_loss, cur_logits = sess.run([loss, logits], feed_dict=feed_dict)\n",
    "                summary_train = sess.run(stat_merged, feed_dict=feed_dict)\n",
    "                summary_writer.add_summary(summary_train, global_step=global_step)\n",
    "                print(\"epoch: {}, global_step: {}, loss: {}, \"\n",
    "                    \"accuracy: {}, f1: {}, auc: {}\".format(\n",
    "                    epoch, global_step, cur_loss,\n",
    "                    calc_accuracy(cur_logits, in_l),\n",
    "                    calc_f1(cur_logits, in_l),\n",
    "                    calc_auc(cur_logits, in_l)))\n",
    "        if cur_loss < best_loss:\n",
    "            best_loss = cur_loss\n",
    "            saver.save(sess, '{}/model'.format(chkpt_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/chkpt/lr/model\n",
      "tp:494.0, tn:473.0, fp:16.0, fn:17.0, acc:0.967, len:1000\n",
      "accuracy: 0.9670000076293945, f1: 0.9676787463271302, auc: 0.9964742935580821\n",
      "weights:  [array([[0.5112941 ],\n",
      "       [0.66312635],\n",
      "       [1.1420636 ],\n",
      "       [1.6672636 ]], dtype=float32)]\n",
      "biases:  [array([0.01430484], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "# predict using checkpoint\n",
    "tf.reset_default_graph()\n",
    "lr = LogisticRegressor(feature_num=FEATURE_NUM, learning_rate=LEARNING_RATE, random_seed=None)\n",
    "saver, logits, loss, train_op, stat_merged = lr.build_graph()\n",
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    saver.restore(sess, '{}/model'.format(chkpt_dir))\n",
    "    \n",
    "    in_feature_vecs = dataset[0][:100]\n",
    "    in_labels = dataset[1][:100]\n",
    "    in_labels = np.expand_dims(in_labels, 1)\n",
    "    feed_dict = {\n",
    "        lr.input_feature_vectors: in_feature_vecs,\n",
    "        lr.input_labels: in_labels\n",
    "    }\n",
    "    out_logits, out_weights, out_biases = sess.run(\n",
    "        [logits, lr.weights, lr.biases], feed_dict=feed_dict)\n",
    "    print(\"accuracy: {}, f1: {}, auc: {}\".format(\n",
    "        calc_accuracy(cur_logits, in_l),\n",
    "        calc_f1(cur_logits, in_l, log_confusion_matrix=True),\n",
    "        calc_auc(cur_logits, in_l)))\n",
    "    print(\"weights: \", out_weights)\n",
    "    print(\"biases: \", out_biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorboard\n",
    "# tensorboard --logdir /tmp/log/lr --port 8008"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
